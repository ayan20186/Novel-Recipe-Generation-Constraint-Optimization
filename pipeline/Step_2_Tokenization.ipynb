{"cells":[{"cell_type":"markdown","source":["**Installing & Importing Required Libraries**"],"metadata":{"id":"GWZkPIPuNfTy"},"id":"GWZkPIPuNfTy"},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"v2TsjoGERiZq"},"id":"v2TsjoGERiZq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import json\n","import h5py\n","import tqdm\n","import numpy as np\n","import pandas as pd\n","import joblib as jb\n","from transformers import GPT2Tokenizer\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"aRvuXwcgNpew"},"id":"aRvuXwcgNpew","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Mounting Google Drive for importing the Data Files which will be used in the Tokenization**"],"metadata":{"id":"kTts_zswOGQ7"},"id":"kTts_zswOGQ7"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"IGpbSsbJOUu5"},"id":"IGpbSsbJOUu5","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Importing Updated Recipe json File which contains Recipe Data**"],"metadata":{"id":"qYIm1rnBN4nn"},"id":"qYIm1rnBN4nn"},{"cell_type":"code","execution_count":null,"metadata":{"id":"weird-allergy"},"outputs":[],"source":["df_new = jb.load('/content/drive/MyDrive/BTP_Dev/Dataset/data_v1.pickle')"],"id":"weird-allergy"},{"cell_type":"markdown","source":["**Converting Recipe json File into a DataFrame**"],"metadata":{"id":"m8pB2zjZObzR"},"id":"m8pB2zjZObzR"},{"cell_type":"code","source":["df = pd.DataFrame(df_new)"],"metadata":{"id":"d8uaLCjDq9cC"},"execution_count":null,"outputs":[],"id":"d8uaLCjDq9cC"},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"QrZYQ2tirGZE"},"execution_count":null,"outputs":[],"id":"QrZYQ2tirGZE"},{"cell_type":"markdown","source":["**Formatting the Instructions of the Recipe by Performing operations like removing '\\t' from the beginning of the instructions, inserting ';' at the end of each instruction, etc**"],"metadata":{"id":"mi5qNn5xOvjc"},"id":"mi5qNn5xOvjc"},{"cell_type":"code","source":["list_of_instrns = []\n","for row in range(0,len(df)):\n","    instr = df.iloc[row]['instructions']\n","\n","    strg = \"\"\n","    length = len(instr) - 1\n","    count = 0\n","    for instruction in instr:\n","        processed_instr = []\n","        for j in range(0,len(instruction)):\n","            if(instruction[j]=='|' or instruction[j]=='\\t'):\n","                continue\n","            elif(instruction[j]==' '):\n","                if(instruction[j-1]!='|'):\n","                   strg = strg + instruction[j]\n","            elif(instruction[j] == '.') and (j!=len(instruction)-1) and (instruction[j-1].isdigit()==False):\n","                strg = strg + ' '\n","                strg = strg + instruction[j]\n","            elif(instruction[j]>='a' and instruction[j]<='z') or (instruction[j]>='A' and instruction[j]<='Z') :\n","                 strg =  strg + instruction[j].lower()\n","            elif(instruction[j] == ','):\n","                  strg =  strg + ' '\n","                  strg =  strg + ','\n","            elif(instruction[j].isdigit()):\n","                if(instruction[j+1] == '.') or (instruction[j+2] == '.'):\n","                    continue\n","                else:\n","                    strg = strg + instruction[j]\n","\n","        if(count!=length):\n","            strg = strg + ' '\n","            strg = strg + ';'\n","            strg = strg + ' '\n","\n","\n","        count = count + 1\n","\n","    processed_instr.append(strg)\n","    list_of_instrns.append(processed_instr)"],"metadata":{"id":"6liGcp0Vz0aL"},"execution_count":null,"outputs":[],"id":"6liGcp0Vz0aL"},{"cell_type":"markdown","source":["**Deleting the current \"instructions\" column from the DataFrame and inserting the modified Instructions by Creating the new \"instructions\" column**"],"metadata":{"id":"MTRskfyTPZqK"},"id":"MTRskfyTPZqK"},{"cell_type":"code","source":["df.drop('instructions', inplace=True, axis=1)"],"metadata":{"id":"thBlxEbU2esx"},"execution_count":null,"outputs":[],"id":"thBlxEbU2esx"},{"cell_type":"code","source":["df['instructions'] = list_of_instrns"],"metadata":{"id":"6z0mlsfx2kmz"},"execution_count":null,"outputs":[],"id":"6z0mlsfx2kmz"},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"FxkhruF-2sll"},"execution_count":null,"outputs":[],"id":"FxkhruF-2sll"},{"cell_type":"markdown","source":["**Dividing whole Data into Train and Test part with the Ratio of Train to Test is 0.96 : 0.04**"],"metadata":{"id":"ziMwJ9oKPttI"},"id":"ziMwJ9oKPttI"},{"cell_type":"code","source":["df.drop('region', axis=1, inplace=True)"],"metadata":{"id":"FKnADMgzALSD"},"id":"FKnADMgzALSD","execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"Sbmpf6NJANEA"},"id":"Sbmpf6NJANEA","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"reserved-heavy","metadata":{"id":"reserved-heavy"},"outputs":[],"source":["train,test = train_test_split(df, train_size=0.96, random_state= 2)"]},{"cell_type":"markdown","source":["**Displaying the Size of Train and Test Part and Resetting to the Default Index of these portions**"],"metadata":{"id":"BIo4YvmTQGSl"},"id":"BIo4YvmTQGSl"},{"cell_type":"code","source":["print(\"Train Portion size is: \",train.shape)\n","print(\"Test Portion size is: \",test.shape)"],"metadata":{"id":"iT38CTW2QL0h"},"id":"iT38CTW2QL0h","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"retired-allen","metadata":{"id":"retired-allen"},"outputs":[],"source":["train.reset_index(drop=True, inplace=True)\n","test.reset_index(drop=True, inplace=True)"]},{"cell_type":"markdown","source":["**Defining the function that will be used for Converting the Dataset into Text Data Format so that the the Data can be Tokenize**"],"metadata":{"id":"liQi9K8dQrQg"},"id":"liQi9K8dQrQg"},{"cell_type":"code","source":["# Identify top 5 cuisines\n","top_cuisines = df['cuisine'].value_counts().nlargest(5).index.tolist()\n"],"metadata":{"id":"JHp4UG-IIWYN"},"id":"JHp4UG-IIWYN","execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_cuisines"],"metadata":{"id":"cLevsgWxJbEC"},"id":"cLevsgWxJbEC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_cuisine_tokens = [f'<CUISINE_{cuisine.upper()}>' for cuisine in top_cuisines]\n","top_cuisine_tokens"],"metadata":{"id":"O8is4BjM_met"},"id":"O8is4BjM_met","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"removed-trailer","metadata":{"id":"removed-trailer"},"outputs":[],"source":["def df_to_plaintext_file(input_df, output_file, top_cuisines):\n","    print(\"Writing to\", output_file)\n","    with open(output_file, 'w', encoding=\"utf-8\") as f:\n","        for index, row in input_df.iterrows():\n","            # Skip the recipes that are not in the top 5 cuisines\n","            if row['cuisine'] not in top_cuisines:\n","                continue\n","\n","            # Add the cuisine token for top 5 cuisines\n","            cuisine_token = f\"<CUISINE_{row['cuisine'].upper()}>\"\n","            title = row.title\n","            instructions = ' '.join(row.instructions).split('.')[:-1]  # Assuming instructions are in a list\n","            ingredients = row.ingredient_phrase\n","            keyword = row.ingredients\n","\n","            # For debugging every 40000 entries\n","            if index % 40000 == 0:\n","                print(index)\n","                print(\"ingreds --->\", ingredients)\n","                print(\"keywords --->\", keyword)\n","\n","            # Construct the formatted text\n","            res = f\"{cuisine_token} <RECIPE_START> <INPUT_START> \" + \" <NEXT_INPUT> \".join(keyword) + \\\n","                  \" <INPUT_END> <TITLE_START> \" + title + \"<TITLE_END> <INGR_START> \" + \\\n","                  \" <NEXT_INGR> \".join(ingredients) + \" <INGR_END> <INSTR_START> \" + \\\n","                  \" <NEXT_INSTR> \".join(instructions) + \" <INSTR_END> <RECIPE_END>\"\n","\n","            f.write(f\"{res}\\n\")"]},{"cell_type":"markdown","source":["**Saving the Processed Train and Test Files to the Custom Path**"],"metadata":{"id":"NO7p7NoCRGCY"},"id":"NO7p7NoCRGCY"},{"cell_type":"code","execution_count":null,"id":"historic-scanner","metadata":{"id":"historic-scanner"},"outputs":[],"source":["df_to_plaintext_file(train, '/content/drive/MyDrive/BTP_Dev/Dataset/train_temp.txt',top_cuisines)\n","df_to_plaintext_file(test, '/content/drive/MyDrive/BTP_Dev/Dataset/test_temp.txt',top_cuisines)"]},{"cell_type":"markdown","source":["**Initializing the GPT2 Tokenizer and Adding special Tokens defined by us to Define the different parts of the Recipe like its title, constituting ingredeints, etc**"],"metadata":{"id":"OP_F-goqRz1S"},"id":"OP_F-goqRz1S"},{"cell_type":"code","execution_count":null,"id":"outer-extent","metadata":{"id":"outer-extent"},"outputs":[],"source":["tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", do_lower_case=False)\n","# tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n","special_tokens = {\n","    \"additional_special_tokens\": [\n","        '<RECIPE_START>',\n","        '<INPUT_START>',\n","        '<NEXT_INPUT>',\n","        '<INPUT_END>',\n","        '<INGR_START>',\n","        '<NEXT_INGR>',\n","        '<INGR_END>',\n","        '<INSTR_START>',\n","        '<NEXT_INSTR>',\n","        '<INSTR_END>',\n","        '<TITLE_START>',\n","        '<TITLE_END>',\n","        '<RECIPE_END>'\n","    ] + top_cuisine_tokens\n","}\n","tokenizer.add_special_tokens(special_tokens)\n","\n","end_token_id = tokenizer.convert_tokens_to_ids([\"<RECIPE_END>\"])[0]\n","\n","hf = h5py.File(\"/content/drive/MyDrive/BTP_Dev/Dataset/data_temp.h5\", \"w\")\n","for filename in [\"/content/drive/MyDrive/BTP_Dev/Dataset/test_temp\", \"/content/drive/MyDrive/BTP_Dev/Dataset/train_temp\"]:\n","    out_np = []\n","    data = open(filename+\".txt\", \"r\")\n","    num = 0\n","    rows = 0\n","    last=[]\n","\n","    # Determine if we are processing the training or test set\n","    is_train = \"train\" in filename\n","\n","    # Get the corresponding part of the DataFrame\n","    current_df = train if is_train else test\n","\n","    for line, (_, row) in zip(data, current_df.iterrows()):\n","        num += 1\n","        if num % 10000 == 0:\n","            print(\"Read \"+str(num)+\" Written: \"+str(rows))\n","\n","        # Add the cuisine token at the start of the line\n","        if row['cuisine'] in top_cuisines:\n","          cuisine_token = f\"<CUISINE_{row['cuisine'].upper()}>\"\n","          line = f\"{cuisine_token} {line}\"\n","        # Tokenization and ID conversion\n","        text_tokens = tokenizer.tokenize(line)\n","        if len(text_tokens) > 1024:\n","            continue\n","        text_tokens_ids = tokenizer.convert_tokens_to_ids(text_tokens)\n","\n","        if (len(last) + len(text_tokens_ids)) <= 1024:\n","            last+=text_tokens_ids\n","        else:\n","            while len(last) < 1024:\n","                last.append(end_token_id)\n","            out_np.append(last)\n","            last=text_tokens_ids\n","            rows+=1\n","    out_mat = np.matrix(out_np)\n","    print(out_mat.shape)\n","    hf.create_dataset(filename, data=out_mat)\n","hf.close()"]},{"cell_type":"markdown","source":["**Displaying the Final Length of Tokenizer**"],"metadata":{"id":"Hd-jXC4BSUBB"},"id":"Hd-jXC4BSUBB"},{"cell_type":"code","execution_count":null,"id":"genuine-production","metadata":{"id":"genuine-production"},"outputs":[],"source":["len(tokenizer)"]},{"cell_type":"markdown","source":["**Displaying the Final Number of Recipes Downsampled**"],"metadata":{"id":"4FpGaVCFSfV6"},"id":"4FpGaVCFSfV6"},{"cell_type":"code","execution_count":null,"id":"cheap-organ","metadata":{"id":"cheap-organ"},"outputs":[],"source":["t = []\n","with open('/content/drive/MyDrive/BTP_Dev/Dataset/train_temp.txt') as file1:\n","    for f in file1:\n","        t.append(f)"]},{"cell_type":"code","execution_count":null,"id":"usual-technical","metadata":{"id":"usual-technical"},"outputs":[],"source":["print('No of recipes downsampled for prototyping: ',len(t))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.7rc1 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.7rc1"},"vscode":{"interpreter":{"hash":"52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}